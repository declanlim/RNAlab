{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import xml.sax\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the BRENDA ontology\n",
    "onto_path.append(\"../../data/ontologies/\")\n",
    "onto = get_ontology('http://purl.obolibrary.org/obo/bto.owl').load()\n",
    "\n",
    "# load classes and synonyms\n",
    "classes = {c.name: c.label.first() for c in onto.classes()}\n",
    "class_synonyms = {c.name: c.hasExactSynonym + c.hasRelatedSynonym for c in onto.classes()}\n",
    "\n",
    "# add additional synonyms\n",
    "class_synonyms['BTO_0000440'] += ['stool']\n",
    "\n",
    "# create a reverse mapping of labels to BRENDA ids\n",
    "# reverse mapping removes redundant end terms from the key where possible\n",
    "redundant_end_terms = ('tissue', 'tissues', 'cell', 'cells')\n",
    "\n",
    "classes_reverse = {c.label.first().lower().strip(): c.name for c in onto.classes() if c.label != []}\n",
    "class_synonyms_reverse = {s.lower().strip(): c for c, syn in class_synonyms.items() for s in syn}\n",
    "labels_reverse = {**classes_reverse, **class_synonyms_reverse}\n",
    "\n",
    "additional_labels = {}\n",
    "for key, value in labels_reverse.items():\n",
    "    if key.endswith(redundant_end_terms):\n",
    "        additional_labels[' '.join(key.split()[:-1])] = value\n",
    "\n",
    "for key, value in additional_labels.items():\n",
    "    if key not in labels_reverse:\n",
    "        labels_reverse[key] = value\n",
    "\n",
    "\n",
    "# flatten the labels and synonyms into a single set\n",
    "class_labels = {c for c in classes.values() if c is not None}\n",
    "class_synonyms_flattend = {s for syn in class_synonyms.values() for s in syn}\n",
    "bto_values = class_labels.union(class_synonyms_flattend)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "redundant_end_terms = ['tissue', 'tissues', 'cell', 'cells']\n",
    "patterns = []\n",
    "\n",
    "for bto_value in bto_values:\n",
    "    weak_pattern = [{'LOWER': token.lower_} for token in tokenizer(bto_value)]\n",
    "    if weak_pattern[-1]['LOWER'] in redundant_end_terms:\n",
    "        weak_pattern[-1]['OP'] = '?'\n",
    "    patterns.append(weak_pattern)\n",
    "\n",
    "matcher.add(\"bto\", patterns=patterns, greedy=\"LONGEST\")\n",
    "\n",
    "# adds a regex pattern to the default tokenizer to split on underscores\n",
    "underscore_tokenizer = nlp.tokenizer\n",
    "infixes = nlp.Defaults.infixes + [r'[_~]']\n",
    "infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "tokenizer.infix_finditer = infix_re.finditer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTO_0000538\n"
     ]
    }
   ],
   "source": [
    "print(labels_reverse['alveolar type 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioSamplesHandler(xml.sax.ContentHandler):\n",
    "    '''\n",
    "    SAX hander class to read in in formation from a BioSamples XMl file\n",
    "    - Reads in the title, paragraph, and attributes of each sample into a dictionary\n",
    "        - if no matching attribtue found, dictionary written as json to file for second pass\n",
    "    - Found values written to provided sample_dict with the biosample_id as the key\n",
    "    '''\n",
    "\n",
    "    def __init__(self, sample_dict, positive_attributes, tmp_file, output_file):\n",
    "        self.sample_dict = sample_dict\n",
    "        self.positive_attributes = positive_attributes\n",
    "        self.tmp_file = tmp_file\n",
    "        self.output_file = output_file\n",
    "        self.biosample_id = ''\n",
    "        self.cur_dict = {}\n",
    "        self.attributes = {}\n",
    "        self.attribute_name = ''\n",
    "        self.is_title = False\n",
    "        self.is_paragraph = False\n",
    "        self.is_sra = False\n",
    "        self.sra_id = ''\n",
    "    \n",
    "    def startDocument(self):\n",
    "        open(self.tmp_file, 'w').close()\n",
    "        open(self.output_file, 'w').close()\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == 'BioSample':\n",
    "            self.biosample_id = attrs['accession']\n",
    "        elif name == 'Title':\n",
    "            self.is_title = True\n",
    "        elif name == 'Paragraph':\n",
    "            self.is_paragraph = True\n",
    "        elif name == 'Attribute':\n",
    "            try:\n",
    "                self.attribute_name = attrs['harmonized_name']\n",
    "            except KeyError:\n",
    "                self.attribute_name = attrs['attribute_name']\n",
    "        elif name == 'Id':\n",
    "            if 'db' in attrs and attrs['db'] == 'SRA':\n",
    "                self.is_sra = True\n",
    "\n",
    "    def characters(self, content):\n",
    "        if self.is_title:\n",
    "            self.cur_dict['title'] = content.lower()\n",
    "            self.is_title = False\n",
    "        elif self.is_paragraph:\n",
    "            self.cur_dict['paragraph'] = content.lower()\n",
    "            self.is_paragraph = False\n",
    "        elif self.is_sra:\n",
    "            self.sra_id = content\n",
    "            self.is_sra = False\n",
    "        elif self.attribute_name != '':\n",
    "            self.attributes[self.attribute_name] = content.lower()\n",
    "            self.attribute_name = ''\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == 'BioSample':\n",
    "            # check if there are any positive attributes and extract the tissue\n",
    "            intersect = set(self.attributes.keys()).intersection(self.positive_attributes)\n",
    "            matches = []\n",
    "            if len(intersect) == 1:\n",
    "                attribute_value = self.attributes[list(intersect)[0]]\n",
    "                # check if the attribute value is a BTO term using the matcher\n",
    "                attribute_tokens = underscore_tokenizer(attribute_value)\n",
    "                matches = matcher(attribute_tokens, as_spans=True)\n",
    "            elif len(intersect) > 1:\n",
    "                # if there are multiple positive attributes, check if any of the values are BTO terms\n",
    "                for attribute in intersect:\n",
    "                    attribute_value = self.attributes[attribute]\n",
    "                    attribute_tokens = underscore_tokenizer(attribute_value)\n",
    "                    matches += matcher(attribute_tokens, as_spans=True)\n",
    "\n",
    "            if matches == []:\n",
    "                # no matches found, write to file\n",
    "                with open(self.tmp_file, 'a') as f:\n",
    "                    self.cur_dict['biosample_id'] = self.biosample_id\n",
    "                    self.cur_dict['attributes'] = self.attributes\n",
    "                    self.cur_dict['sra_id'] = self.sra_id\n",
    "                    json.dump(self.cur_dict, f)\n",
    "                    f.write('\\n')\n",
    "            else:\n",
    "                # matches found, add to sample_dict\n",
    "                tissue_matches = ','.join([m.text for m in matches])\n",
    "                bto_matches = ','.join([labels_reverse[m.text.lower()] for m in matches])\n",
    "                with open(self.output_file, 'a') as f:\n",
    "                    json.dump({'biosample_id': self.biosample_id , 'sra_id': self.sra_id, 'tissue': tissue_matches, 'bto_matches': bto_matches}, f)\n",
    "                    f.write('\\n')\n",
    "                \n",
    "            self.attribute_name = ''\n",
    "            self.attributes = {}\n",
    "            self.cur_dict = {}\n",
    "            self.biosample_id = ''\n",
    "            self.sra_id = ''\n",
    "\n",
    "\n",
    "    def endDocument(self):\n",
    "        print(\"Finished parsing BioSamples XML file\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished parsing BioSamples XML file\n"
     ]
    }
   ],
   "source": [
    "positive_attributes = {'tissue', 'cell_type', 'cell_line', 'cell_subtype', 'source_name', 'host_tissue_sampled'}\n",
    "sample_dict = {}\n",
    "\n",
    "# parse the BioSamples XML file\n",
    "parser = xml.sax.make_parser()\n",
    "handler = BioSamplesHandler(sample_dict, positive_attributes, 'tmp.jsonl', 'output.jsonl')\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "parser.parse('../../data/biosamples/biosample_random_samples.xml')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
