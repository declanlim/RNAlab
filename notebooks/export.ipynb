{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Exporting data\n",
    "- Want to export the results of the different maps to a csv for easy input to Postgres\n",
    "    - data for the temp_map already exported from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Tissue map\n",
    "- results of tissue map located in two different jsonl files\n",
    "- each biosample_id has one SRS associated with it and a number of tissue / bto_ids associated with it\n",
    "- for each biosample, want to create a row that has the biosample_id, sra_id, tissue, and BTO_id\n",
    "    - if there are multiple hits for the tissue / BTO_id, these should be in separate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results of the tissue_map into a single dataframe \n",
    "tissue_df_1 = pd.read_json('../../data/results/tissue_output_1.jsonl', lines=True)\n",
    "tissue_df_2 = pd.read_json('../../data/results/tissue_output_2.jsonl', lines=True)\n",
    "tissue_df = pd.concat([tissue_df_1, tissue_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(writer, row):\n",
    "    biosample_id = row['biosample_id']\n",
    "    run_id = row['sra_id']\n",
    "    tissue = row['tissue']\n",
    "    bto_id = row['bto_matches']\n",
    "    for tissue_split, bto_id_split in zip(tissue.split(','), bto_id.split(',')):\n",
    "        writer.writerow([biosample_id, run_id, tissue_split, bto_id_split])\n",
    "\n",
    "\n",
    "with open('../exports/tissue_map.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['biosample_id', 'run_id', 'tissue', 'bto_id'])\n",
    "    tissue_df.apply(lambda row: write_to_file(writer, row), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue map rerun export\n",
    "- create dataframe for new rerun data\n",
    "- previous table deleted in postgres to avoid conflicts\n",
    "----\n",
    "- rerun after fixing bugs for multiple matches in single source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results of the tissue_map into a single dataframe \n",
    "tissue_df_1 = pd.read_json('../../data/results/tissue_output_1_rerun.jsonl', lines=True)\n",
    "tissue_df_2 = pd.read_json('../../data/results/tissue_output_2_rerun.jsonl', lines=True)\n",
    "tissue_df = pd.concat([tissue_df_1, tissue_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220    BTO_0000725\\tBTO_0001413\n",
      "Name: bto_matches, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tissue_df[tissue_df['biosample_id'] == \"SAMN00002389\"][\"bto_matches\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tissue', 'cell_type', 'cell_type']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"biosample_id\": \"SAMN04571587\", \"sra_id\": \"\", \"source\": \"tissue\\tcell_type\\tcell_type\", \"text\": \"ear\\tear fibroblast culture, passage 3\\tear fibroblast culture, passage 3\", \"tissue\": \"ear\\tear\\tfibroblast\", \"bto_matches\": \"BTO_0000368\\tBTO_0000368\\tBTO_0000452\"}\n",
    "a[\"source\"].split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(writer, row):\n",
    "    biosample_id = row['biosample_id']\n",
    "    srs_id = row['sra_id']\n",
    "    tissue = row['tissue']\n",
    "    source = row['source']\n",
    "    text = row['text']\n",
    "    bto_id = row['bto_matches']\n",
    "    # store a set of existing bto_ids to avoid duplicates\n",
    "    existing_matches = set()\n",
    "    for source_split, text_split, tissue_split, bto_id_split in zip(source.split('\\t'), text.split('\\t'), tissue.split('\\t'), bto_id.split('\\t')):\n",
    "        # skip if the tissue has already been identified\n",
    "        if bto_id_split in existing_matches:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow([biosample_id, srs_id, source_split, text_split, tissue_split, bto_id_split])\n",
    "            existing_matches.add(bto_id_split)\n",
    "\n",
    "\n",
    "with open('../exports/tissue_map_rerun.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['biosample_id', 'srs_id', 'source', 'text', 'tissue', 'bto_id'])\n",
    "    tissue_df.apply(lambda row: write_to_file(writer, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gonzalez et al \"genomic analysis provides insights into the functional capacity of soil bacteria communities inhabiting an altitudinal gradient in the atacama desert.\" microbiome journal (to be submitted)', ''],soil alkaline flat,soil metagenome\n"
     ]
    }
   ],
   "source": [
    "for t in (tissue_df[tissue_df['biosample_id'] == 'SAMN18623547']['text']):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples like 'SAMEA112151282' cause issues where a large experiment description is included in the xml. Returns multiple different hits:\n",
    "\n",
    "- ovary\n",
    "- digestive tube \n",
    "- bile\n",
    "- gut\n",
    "- feces\n",
    "- digestive system\n",
    "- liver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Sex\n",
    "- sex_output file has a line for each biosample \n",
    "- each line can be directly written to a csv for postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_df = pd.read_json('../../data/results/sex_output_1.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(writer, row):\n",
    "    biosample_id = row['biosample_id']\n",
    "    run_id = row['sra_id']\n",
    "    male = bool(row['male']) if not np.isnan(row['male']) else ''\n",
    "    female = bool(row['female']) if not np.isnan(row['female']) else ''\n",
    "    other = bool(row['other']) if not np.isnan(row['other']) else ''\n",
    "    writer.writerow([biosample_id, run_id, male, female, other])\n",
    "\n",
    "with open('../exports/sex_map.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['biosample_id', 'run_id', 'male', 'female', 'other'])\n",
    "    sex_df.apply(lambda row: write_to_file(writer, row), axis=1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
